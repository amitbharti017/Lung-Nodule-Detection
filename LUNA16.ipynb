{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93b308cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3491b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b65f325",
   "metadata": {},
   "source": [
    "#### Importing annotations and candidates csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37017ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = pd.read_csv(\"dataset/annotations.csv\")\n",
    "candidates =pd.read_csv(\"dataset/candidates_V2/candidates_V2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85eb8216",
   "metadata": {},
   "source": [
    "#### The candidates file is a csv file that contains nodule candidate per line. Each line holds the scan name, the x, y, and z position of each candidate in world coordi-nates, and the corresponding class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67d25aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 754975 entries, 0 to 754974\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   seriesuid  754975 non-null  object \n",
      " 1   coordX     754975 non-null  float64\n",
      " 2   coordY     754975 non-null  float64\n",
      " 3   coordZ     754975 non-null  float64\n",
      " 4   class      754975 non-null  int64  \n",
      "dtypes: float64(3), int64(1), object(1)\n",
      "memory usage: 28.8+ MB\n"
     ]
    }
   ],
   "source": [
    "candidates.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9da20c6",
   "metadata": {},
   "source": [
    "#### The annotation file is a csv file that contains one finding per line. Each line holds the Series Instance UID of the scan, the x, y, and z position of each finding in world coordinates; and the corresponding diameter in mm. The annotation file contains 1186 nodules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "556837c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1186 entries, 0 to 1185\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   seriesuid    1186 non-null   object \n",
      " 1   coordX       1186 non-null   float64\n",
      " 2   coordY       1186 non-null   float64\n",
      " 3   coordZ       1186 non-null   float64\n",
      " 4   diameter_mm  1186 non-null   float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 46.5+ KB\n"
     ]
    }
   ],
   "source": [
    "annotations.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65055653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "753418\n",
      "1557\n",
      "percentage of positive cases are 0.20623199443690188 %\n"
     ]
    }
   ],
   "source": [
    "##################### Samples are heavily imbalanced #####################\n",
    "\n",
    "print(len(candidates[candidates['class'] == 0]))\n",
    "print(len(candidates[candidates['class'] == 1]))\n",
    "print ('percentage of positive cases are ' + str(len(candidates[candidates['class'] == 1])*100.0/len(candidates))+\" %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a9f8882",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ct_scan_processing(object):\n",
    "    \"\"\"\n",
    "    Class that manipulates and processes over images in the dataset using SimpleITK tools and PIL library.\n",
    "    Is responsible for:\n",
    "    1. Read the image from specified filename\n",
    "    2. Convert the image into it's array representation,\n",
    "    3. Get coordinates corresponding to origin, voxel,\n",
    "    4. Reset the coordinates of the original image,\n",
    "    5. Normalizes the image, \n",
    "    6. Writing the modified image back to the file.\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, filename = None, coords = None, path = None):\n",
    "        \"\"\"\n",
    "        Constructor to initialize file name, coordinates, image array and PIL image object.\n",
    "        \n",
    "        \"\"\"\n",
    "        self.filename = filename\n",
    "        self.coords = coords\n",
    "        self.ds = None\n",
    "        self.image = None\n",
    "        self.file_storage_location = path\n",
    "\n",
    "    def set_coords(self, coords):\n",
    "        self.coords = coords\n",
    "\n",
    "    def read_mhd_image(self):\n",
    "        file_storage_location = glob.glob('dataset/seg-lungs-LUNA16/'+self.filename+'*.mhd', recursive =True)\n",
    "        # Reads the image using SimpleITK\n",
    "        self.ds = sitk.ReadImage(file_storage_location[0])\n",
    "        #print(self.ds)\n",
    "         # Convert the image to a  numpy array\n",
    "        self.image = sitk.GetArrayFromImage(self.ds)\n",
    "\n",
    "    def get_resolution(self):\n",
    "        return self.ds.GetSpacing()\n",
    "\n",
    "    def get_origin(self):\n",
    "        return self.ds.GetOrigin()\n",
    "\n",
    "    def get_ds(self):\n",
    "        return self.ds\n",
    "    def get_voxel_coords(self):\n",
    "        origin = self.get_origin()\n",
    "        resolution = self.get_resolution()\n",
    "        voxel_coords = [np.absolute(self.coords[j]-origin[j])/resolution[j] \\\n",
    "            for j in range(len(self.coords))]\n",
    "        return tuple(voxel_coords)\n",
    "    \n",
    "    def get_image(self):\n",
    "        return self.image\n",
    "    \n",
    "    def get_subimage(self, width):\n",
    "        self.read_mhd_image()\n",
    "        x, y, z = self.get_voxel_coords()\n",
    "        subImage = self.image[int(z), int(y-width/2):int(y+width/2), int(x-width/2):int(x+width/2)]\n",
    "        return subImage   \n",
    "    \n",
    "    def normalizePlanes(self, npzarray):\n",
    "        \"\"\"\n",
    "        Normalizing the image using the appropriate maximum and minimum values associated \n",
    "        with a CT scan for lung cancer (in terms of Hounsfeld Units)\n",
    "        \n",
    "        \"\"\"\n",
    "        max_hu = 200.\n",
    "        min_hu= -1000.\n",
    "        npzarray = (npzarray - min_hu) / (max_hu - min_hu)\n",
    "        npzarray[npzarray>1] = 1.\n",
    "        npzarray[npzarray<0] = 0.\n",
    "        return npzarray\n",
    "    \n",
    "    def save_image(self, filename, width):\n",
    "        \"\"\"\n",
    "        Converts the normalized cropped image into a grayscale image and store in\n",
    "        the filename argument specified location.\n",
    "        \n",
    "        \"\"\"\n",
    "        image = self.get_subimage(width)\n",
    "        image = self.normalizePlanes(image)\n",
    "        Image.fromarray(image*255).convert('L').save(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d56d3c",
   "metadata": {},
   "source": [
    "An .mhd file, which is a header file containing metadata describing image properties such as voxel size, matrix size, orientation and position, and a link to the binary image. This file can also contain limited metadata information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237b164f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5ba0d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6999aa3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BCDU_net_D3(input_size = (256,256,1)):\n",
    "    N = input_size[0]\n",
    "    inputs = Input(input_size) \n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "  \n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "    drop3 = Dropout(0.5)(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    # D1\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)     \n",
    "    conv4_1 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "    drop4_1 = Dropout(0.5)(conv4_1)\n",
    "    # D2\n",
    "    conv4_2 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(drop4_1)     \n",
    "    conv4_2 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4_2)\n",
    "    conv4_2 = Dropout(0.5)(conv4_2)\n",
    "    # D3\n",
    "    merge_dense = concatenate([conv4_2,drop4_1], axis = 3)\n",
    "    conv4_3 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge_dense)     \n",
    "    conv4_3 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4_3)\n",
    "    drop4_3 = Dropout(0.5)(conv4_3)\n",
    "    \n",
    "    up6 = Conv2DTranspose(256, kernel_size=2, strides=2, padding='same',kernel_initializer = 'he_normal')(drop4_3)\n",
    "    up6 = BatchNormalization(axis=3)(up6)\n",
    "    up6 = Activation('relu')(up6)\n",
    "\n",
    "    x1 = Reshape(target_shape=(1, np.int32(N/4), np.int32(N/4), 256))(drop3)\n",
    "    x2 = Reshape(target_shape=(1, np.int32(N/4), np.int32(N/4), 256))(up6)\n",
    "    merge6  = concatenate([x1,x2], axis = 1) \n",
    "    merge6 = ConvLSTM2D(filters = 128, kernel_size=(3, 3), padding='same', return_sequences = False, go_backwards = True,kernel_initializer = 'he_normal' )(merge6)\n",
    "            \n",
    "    conv6 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "    conv6 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "    up7 = Conv2DTranspose(128, kernel_size=2, strides=2, padding='same',kernel_initializer = 'he_normal')(conv6)\n",
    "    up7 = BatchNormalization(axis=3)(up7)\n",
    "    up7 = Activation('relu')(up7)\n",
    "\n",
    "    x1 = Reshape(target_shape=(1, np.int32(N/2), np.int32(N/2), 128))(conv2)\n",
    "    x2 = Reshape(target_shape=(1, np.int32(N/2), np.int32(N/2), 128))(up7)\n",
    "    merge7  = concatenate([x1,x2], axis = 1) \n",
    "    merge7 = ConvLSTM2D(filters = 64, kernel_size=(3, 3), padding='same', return_sequences = False, go_backwards = True,kernel_initializer = 'he_normal' )(merge7)\n",
    "        \n",
    "    conv7 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "    conv7 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "    up8 = Conv2DTranspose(64, kernel_size=2, strides=2, padding='same',kernel_initializer = 'he_normal')(conv7)\n",
    "    up8 = BatchNormalization(axis=3)(up8)\n",
    "    up8 = Activation('relu')(up8)    \n",
    "\n",
    "    x1 = Reshape(target_shape=(1, N, N, 64))(conv1)\n",
    "    x2 = Reshape(target_shape=(1, N, N, 64))(up8)\n",
    "    merge8  = concatenate([x1,x2], axis = 1) \n",
    "    merge8 = ConvLSTM2D(filters = 32, kernel_size=(3, 3), padding='same', return_sequences = False, go_backwards = True,kernel_initializer = 'he_normal' )(merge8)    \n",
    "    \n",
    "    conv8 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "    conv8 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "    conv8 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "    conv9 = Conv2D(1, 1, activation = 'sigmoid')(conv8)\n",
    "\n",
    "    model = Model(inputs, conv9)\n",
    "    #model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])    \n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
